name: github-crawler

on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  crawler:
    runs-on: ubuntu-latest

    container: python:3.11-slim

    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_PASSWORD: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Postgres client
        run: |
          apt-get update
          apt-get install -y postgresql-client

      - name: Install Python deps
        run: pip install -r requirements.txt

      - name: Setup database schema
        env:
          PGHOST: postgres
          PGUSER: postgres
          PGPASSWORD: postgres
          PGDATABASE: postgres
        run: |
          psql -h postgres -U postgres -f scripts/setup_db.sql

      - name: Crawl 100k GitHub repos
        env:
          PGHOST: postgres
          PGUSER: postgres
          PGPASSWORD: postgres
          PGDATABASE: postgres
          GITHUB_TOKEN: ${{ github.token }}
        run: python scripts/crawl_stars.py

      - name: Dump DB to CSV
        env:
          PGHOST: postgres
          PGUSER: postgres
          PGPASSWORD: postgres
          PGDATABASE: postgres
        run: python scripts/dump.py

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: repo-stars-dump
          path: /tmp/repos.csv